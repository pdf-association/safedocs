# **Compacted PDF Syntax**

The compacted PDF syntax test file is for testing PDF lexical analyzers to ensure they comply with some of the finer points of the PDF standard and to ensure interoperability between implementations.

The old Adobe PDF 1.3 Specification (circa 2000), section 3.1.1 Character Set states:
> The delimiter characters (, ), <, >, [, ], {, }, /, and % are special. They delimit syntactic entities such as strings, arrays, names, and comments. Any of these characters terminates the entity preceding it and is not included in the entity.

ISO 32000-1:2008 (PDF 1.7) clause 7.2.2 Character Set states:
> The delimiter characters (, ), <, >, [, ], {, }, /, and % are special (LEFT PARENTHESIS (28h), RIGHT PARENTHESIS (29h), LESS-THAN SIGN (3Ch), GREATER-THAN SIGN (3Eh), LEFT SQUARE BRACKET (5Bh), RIGHT SQUARE BRACKET (5Dh), LEFT CURLY BRACE (7Bh), RIGHT CURLY BRACE (07Dh), SOLIDUS (2Fh) and PERCENT SIGN (25h), respectively). They delimit syntactic entities such as arrays, names, and comments. Any of these characters terminates the entity preceding it and is not included in the entity. Delimiter characters are allowed within the scope of a string when following the rules for composing strings; see 7.3.4.2, "Literal Strings”. The leading ( of a string does delimit a preceding entity and the closing ) of a string delimits the string’s end.

ISO 32000-2:2017 (PDF 2.0) clause 7.2.3 Character set stated:
> The delimiter characters (, ), <, >, [, ], {, }, /, and % are special (LEFT PARENTHESIS (28h), RIGHT PARENTHESIS (29h), LESS-THAN SIGN (3Ch), GREATER-THAN SIGN (3Eh), LEFT SQUARE BRACKET (5Bh), RIGHT SQUARE BRACKET (5Dh), LEFT CURLY BRACE (7Bh), RIGHT CURLY BRACE (7Dh), SOLIDUS (2Fh) and PERCENT SIGN (25h), respectively). They delimit syntactic entities such as arrays, names, and comments. In addition, the double character constructs << (3C3Ch) and >> (3E3Eh) are used to delimit dictionary objects (see 7.3.7, "Dictionary objects"). Any of these delimiters terminates the entity preceding it and is not included in the entity. Delimiter characters are allowed within the scope of a string when following the rules for composing strings; see 7.3.4.2, "Literal strings". The leading ( of a string does delimit a preceding entity and the closing ) of a string delimits the string’s end. "Table 2 — Delimiter characters” shows the delimiter characters.

And the most recent ISO 32000-2:2020 clause 7.2.3 Character set states:
> The delimiter characters (, ), <, >, [, ], /, and % are special (LEFT PARENTHESIS (28h), RIGHT PARENTHESIS (29h), LESS-THAN SIGN (3Ch), GREATER-THAN SIGN (3Eh), LEFT SQUARE BRACKET (5Bh), RIGHT SQUARE BRACKET (5Dh), SOLIDUS (2Fh) and PERCENT SIGN (25h), respectively). They delimit syntactic entities such as arrays, names, and comments. The delimiter characters { and } (LEFT CURLY BRACE (7Bh) and RIGHT CURLY BRACE (7Dh)) are additional delimiter characters within Type 4 PostScript calculator functions (see 7.10.5 "Type 4 (PostScript calculator) functions"). In addition, the double character constructs << (3C3Ch) and >> (3E3Eh) are used to delimit dictionary objects (see 7.3.7, "Dictionary objects"). Any of these delimiters terminates the entity preceding it and is not included in the entity. Delimiter characters are allowed within the scope of a string when following the rules for composing strings; see 7.3.4.2, "Literal strings". The leading ( of a string does delimit a preceding entity and the closing ) of a string delimits the string’s end. "Table 2 — Delimiter characters” shows the delimiter characters.

Fundamentally there have been no changes to the basic lexical rules of PDF! Only corrections (such as recognizing that `LEFT CURLY BRACE` and `RIGHT CURLY BRACE` are not token delimiters in general PDF, but a hangover from PostScript!) and clarifications (such as improved cross referencing to other clauses and highlighting the double character constructs used by dictionaries). When considered logically and based on a detailed reading of the PDF specification, any adjacent pair of PDF tokens may or may not require whitespace as the token delimiter. This will depend on the specific rules for the bytes that comprise each token, and whether a specific delimiter character is included or not.

A key point is that PDF does **NOT** always require whitespace between tokens and that various other characters are also explicit token delimiters. This is explicitly noted in all PDF specifications where additional whitespace is used to aid clarity of examples. It is  common to encounter certain PDF objects without whitespace between adjacent tokens and that relies on the above token delimiter rules in extant data:

* PDF name objects: `/Type/XObject`;
* PDF dictionaries when written as direct objects: `<</SomeKey<</A/B>>>>`;
* direct nested PDF arrays: `[[/A/B][/C/D]]`;
* PDF hex strings: `<0a><0d>`; and
* PDF literal strings: `(cat)(mat)`.

However some characters (such as `PERCENT SIGN`) are often not handled correctly as a token delimiter - and this can lead to parser differentials, non-interoperable PDFs or worse - parser crashes.

A matrix document (also a PDF) describing the 121 possible token pairings is provided. This illustrates that in some cases multiple characters can be used as the first character in a token, creating even more combinations of adjacent character pairings (e.g., a real number can start with sign `-` or `+` (i.e., a negative number such as `-1.2`), `.` (US-style decimal point, as in `.123`) or any of the digits `0` to `9` (such as `4.56`) so there are 3 test cases for when a PDF real number is the second token). This creates multiple possible adjacent character pairings that are valid token pairs after, for example, the PDF array close token (`]`) : `]-1.2`, `]+1.2`, `].12` and `]4.56`.

The provided PDF test file has been carefuly hand-crafted to use a valid but highly compacted syntax (i.e. avoidance of whitespace) with hopefully(!) all combinations of permitted adjacent PDF tokens/character pairs. This is constructed for both the body of the PDF file as well as in a content stream (for those token pairs permitted in content streams). The data is ordered such that the test data occurs before the necessary valid PDF constructs required to make a valid PDF so that a parser must first process the compacted token and character pairings. The PDF file can be opened in most text editors for inspection, however do **NOT** re-save or repair this file!! It is specifically targeted at technical software developers of PDF lexical analyzers. A correct rendering (visual appearance) of this PDF alone does **NOT** guarantee that a PDF processor correctly processes tokens according to all the PDF rules - an analysis of the parsed token stream or confirmation of the constructed PDF DOM against the PDF file is required.

File `CompactedPDFSyntaxTest.pdf.json` provides a JSON representation of the PDF test file and can be used to assert correctness of the PDF lexical analyzer.

___
*This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No. HR001119C0079. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the Defense Advanced Research Projects Agency (DARPA). Approved for public release.*

